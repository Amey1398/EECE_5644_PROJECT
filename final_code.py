# -*- coding: utf-8 -*-
"""final_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NGptU2yyXXssr8iYT6vWJ9u4Axc5oM1G

## **Market Customer Segmentation with SVM Classifier and K-Means**

IMPORTS
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install kneed

import pandas as pd
import numpy as np
# Necessary imports
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
from matplotlib import pyplot
import plotly.express as px
from kneed import KneeLocator
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold, GridSearchCV, StratifiedKFold
from sklearn.metrics import roc_auc_score, accuracy_score
from sklearn.svm import SVC
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.impute import KNNImputer
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn import preprocessing, decomposition
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import auc
from sklearn.cluster import KMeans
from sklearn.metrics import roc_curve
from sklearn.tree import DecisionTreeRegressor
from plotly.subplots import make_subplots
import plotly.graph_objects as go
import plotly.express as px
import plotly.offline 


np.set_printoptions(suppress=True)

# Set seed to generate reproducible "pseudo-randomness" (handles scipy's "randomness" too)
np.random.seed(7)

plt.rc('font', size=22)          # controls default text sizes
plt.rc('axes', titlesize=18)     # fontsize of the axes title
plt.rc('axes', labelsize=18)     # fontsize of the x and y labels
plt.rc('xtick', labelsize=14)    # fontsize of the tick labels
plt.rc('ytick', labelsize=14)    # fontsize of the tick labels
plt.rc('legend', fontsize=16)    # legend fontsize
plt.rc('figure', titlesize=22)   # fontsize of the figure title

"""**PRE-PROCESSING**"""

df = pd.read_csv('Train.csv')
df1 = pd.read_csv('Test.csv')
print(f'\nTrain data shape - {df.shape}')
print(f'\nTest data shape - {df1.shape}')

df.head(3)

df.info()

df.describe()

df.isnull().sum()

null_df = pd.concat([pd.DataFrame(df.isna().sum()),pd.DataFrame(df1.isna().sum())],axis=1)
null_df.columns = ["Train_Nan","Test_Nan"]
null_df

# How many unique values are in Columns of Data Train ?
listoftrain=[]
print("Total Train Data :",len(df))
for i in df.columns:
  print(f'{i}:',len(df[i].unique()))
  print(f'{i} Nan Values: :',sum(df[i].isna()))
  listoftrain.append(i)
  listoftrain.append(len(df[i].unique()))
  listoftrain.append(sum(df[i].isna()))
  if df[i].dtype=="int64":
    print(f'{i} Mean:',df[i].mean())
    listoftrain.append(df[i].mean())
  else:
    print(f'{i} Mode:',df[i].mode().values[0])
    listoftrain.append(df[i].mode().values[0])

#Train_data_result=pd.DataFrame(np.array(listoftrain).reshape((10,4)),columns=["Feature","Unique","NanValues","Mode"])

#Removing the Nans using KNN
df_train = df.copy()
df_test = df1.copy()
def get_encoded_dict(df,lst):
    """
    this function creates dictionary for encoding. Its find unique labels for each column and enumerate them
    
    Arguments:
    df -- pandas dataframe
    lst -- list of columns which we want to encode 
    
    Returns:
    dictionary where key is column name and value is dictionary of unique labels and encoding value
    """
    encoded_dict = {}
    for col in lst:
        each_dict = {}
        sorted_unique_names = df[col].dropna().unique()
        sorted_unique_names.sort()
        for i,val in enumerate(sorted_unique_names):
            each_dict[val] = i
        encoded_dict[col] = each_dict
    return encoded_dict

encoded_dict = get_encoded_dict(df_train,["Gender","Ever_Married","Graduated","Profession","Spending_Score","Var_1","Segmentation"])
duplicates = df_train[df_train.duplicated(subset = df_train.columns.drop("Segmentation"))]
duplicates = duplicates.replace(encoded_dict)
df_train = df_train.replace(encoded_dict)
df_test = df_test.replace(encoded_dict)

imputer = KNNImputer()
df_train[df_train.columns.drop(["ID","Segmentation"])] = np.round(imputer.fit_transform(df_train.drop(columns = ["ID","Segmentation"])))

df_test[df_test.columns.drop(["ID"])] = np.round(imputer.fit_transform(df_test.drop(columns = ["ID"])))

null_df = pd.concat([pd.DataFrame(df_train.isna().sum()),pd.DataFrame(df_test.isna().sum())],axis=1)
null_df.columns = ["Train_Nan","Test_Nan"]
null_df

for i in df.columns:
  if sum(df[i].isna())!=0:
    df[i+"_add_val"] = df[i].isna()
  if i!= ["Age","Work_Experience","Family_Size"]:
    df[i]=df[i].fillna(df[i].mode().values[0])
  else:
    df[i]=df[i].fillna(df[i].mean())

"""EXPLORATORY DATA ANALYSIS"""

plot_data = df.groupby('Segmentation')['Segmentation'].agg(['count']).reset_index()
fig = px.pie(plot_data, values = plot_data['count'], names = plot_data['Segmentation'])
fig.update_traces(textposition = 'inside', textinfo = 'percent + label', hole = 0.5, 
                  marker = dict(colors = ['	#FF4040','#98F5FF', '	#76EE00', '	#6495ED'], line = dict(color = 'white', width = 2)))
fig.update_layout(title_text = 'Customer<br>Segmentation', title_x = 0.5, title_y = 0.55, title_font_size = 26, 
                  title_font_family = 'Calibri', title_font_color = 'black', showlegend = False)              
fig.show()

f, ax  = plt.subplots(2,2,figsize = (20,10))
colors=["#FF7C00", "#E8000B","#1AC938"]
df['Gender'].value_counts().plot.pie(title='Distribution of Gender',explode=[0,.1],
                                           ax=ax[0][0],autopct="%.2f",shadow = True,colors = colors)

df['Ever_Married'].value_counts().plot.pie(title='Distribution of Ever_Married',explode=[0,.1],
                                                 ax=ax[0][1],autopct="%.2f",shadow = True,colors = colors)

df['Graduated'].value_counts().plot.pie(title='Distribution of Graduated',explode=[0,.1],
                                              ax=ax[1][0],autopct="%.2f",shadow = True,colors = colors)

df['Spending_Score'].value_counts().plot.pie(title='Distribution of Spending_Score',
                                                   ax=ax[1][1],explode=[0,.1,.1],autopct="%.2f",shadow = True,colors=colors)
f.patch.set_facecolor('white')
plt.show()

f, ax  = plt.subplots(4,1,figsize = (7,14))
colors=["#023EFF","#FF7C00", "#E8000B","#1AC938"]
labels = ["D","C","A","B"]

ax1 = sns.countplot(df['Profession'],ax=ax[0],palette = "Paired")
ax1.set_xticklabels(ax1.get_xticklabels(), rotation=40, ha="right")

sns.countplot(df['Work_Experience'],ax=ax[1],palette = "Paired")
sns.countplot(df['Family_Size'],ax=ax[2],palette = "Paired")
sns.countplot(df['Var_1'],ax=ax[3],palette = "Paired")

f, ax = plt.subplots(figsize=(12, 6))

sns.countplot(df_train['Segmentation'],palette = "bright")

# Function for plotting different categorcial features affect on target variable (Segmentation)
def plot_pie(feature, df=None):
    data = df
    plot_data = data.groupby([feature, 'Segmentation'])[feature].agg({'count'}).reset_index()

    fig = px.sunburst(plot_data, path = [feature, 'Segmentation'], values = 'count', color = feature, 
                      title = 'Affect of %s on Customer Segmentation'%feature, width = 600, height = 600)

    fig.update_layout(plot_bgcolor = 'white', title_font_family = 'Calibri Black', title_font_color = '#221f1f', 
                      title_font_size = 22, title_x = 0.5)

    fig.update_traces(textinfo = 'label + percent parent')
    fig.show()
  
for feature in ['Gender', 'Ever_Married', 'Graduated', 'Spending_Score']:
  plot_pie(feature, df=df)

# Functions for plotting different numerical features affect on target variable (Segmentation)
def plot_numerical(feature, figsize=None, df=None):
    data = df
    fig = plt.figure(figsize=(10,6))

    sns.kdeplot(data[data['Segmentation']=='A'][feature], cut = 0)
    sns.kdeplot(data[data['Segmentation']=='B'][feature], cut = 0)
    sns.kdeplot(data[data['Segmentation']=='C'][feature], cut = 0)
    sns.kdeplot(data[data['Segmentation']=='D'][feature], cut = 0)

    fig.legend(labels=['Segmentation A', 'Segmentation B', 'Segmentation C', 'Segmentation D'])
    plt.title('Based on %s'%feature)
    plt.show()

for feature in ['Age', 'Work_Experience', 'Family_Size']:
    plot_numerical(feature, df=df)

train = df
ecdf_train = train.sort_values(by=['Segmentation'])
sns.ecdfplot(data=ecdf_train , x='Age' , hue= 'Segmentation')
plt.grid()

"""MODELLING WITH SUPERVISED TECHNIQUES"""

#Train test split
#Split data into train and validation sets
X_train, X_test, y_train, y_test = train_test_split(df_train.iloc[:,:-1], df_train.iloc[:, -1], test_size=0.2, random_state=42)

#Scaling the data
scaler = MinMaxScaler()
columns_to_normalize = ['Age','Profession','Work_Experience','Spending_Score','Family_Size','Var_1']

X_train[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])
X_test[columns_to_normalize] = scaler.fit_transform(X_test[columns_to_normalize])

df_train[columns_to_normalize] = scaler.fit_transform(df_train[columns_to_normalize])
df_test[columns_to_normalize] = scaler.fit_transform(df_test[columns_to_normalize])

X_train.head(3)

"""SUPPORT VECTOR MACHINES (SVM)"""

df_train_svm_X = df_train.iloc[:, 1:-1]
df_train_svm_y = df_train.iloc[:,-1]

# 10-fold CV
K = 10

# Set up parameters to evaluate using GridSearchCV
C_range = np.logspace(-3, 3, 7)
#C_range = np.array((0.1, 1))
gamma_range = np.logspace(-3, 3, 7)
#gamma_range = np.array((0.1, 1))
param_grid = {'C':C_range, 'kernel':['rbf'], 'gamma':gamma_range}
        

# Specifying that we'll use the Gaussian kernel
svc = SVC()
cv = StratifiedKFold(n_splits=K)
classifier = GridSearchCV(estimator=svc, param_grid=param_grid, cv=cv, verbose = 5)
classifier.fit(df_train_svm_X, df_train_svm_y)
kernel_best = classifier.best_params_['kernel']
C_best = classifier.best_params_['C']
gamma_best = classifier.best_params_['gamma']
print(f"Best Kernel: {kernel_best}")
print("Best Regularization Strength 'C': %.3f" % C_best)
print("Best Kernel Width 'gamma': %.3f" % gamma_best)
print("SVM CV Pr(error): %.3f" % (1-classifier.best_score_))

# Plot Pr(error) vs regularization parameter when gamma is held constant
C_data = classifier.cv_results_['param_C'].data
gamma_data = classifier.cv_results_['param_gamma'].data
cv_prob_error = 1 - classifier.cv_results_['mean_test_score']
plt.figure(figsize=(10, 10))
# Iterate over each gamma in the parameter grid
for g in gamma_range:
    # Find what C values correspond to a specific gamma
    C = C_data[gamma_data == g]
    # Sort in ascending order
    sort_idx = C.argsort()[::-1]
    # Pick out the error associated with that gamma and C combo
    prob_error = cv_prob_error[gamma_data == g]
    plt.plot(C[sort_idx], prob_error[sort_idx], label=fr"$\gamma = {g}$")

plt.title("Probability Error for 10-fold Cross-Validation on SVM")
plt.xscale('log')
plt.xlabel(r"$C$")
plt.ylabel("Pr(error)")
plt.legend()
plt.show()

classifier.best_params_

#Check performance on train set
y_predict_train = classifier.predict(df_train_svm_X)
acc_train = accuracy_score(df_train_svm_y, y_predict_train)
print("Accuracy for SVM: ", acc_train)

from sklearn.metrics import confusion_matrix
cm_train = confusion_matrix(df_train_svm_y.values, y_predict_train, labels=[0,1,2,3])
print('\n\n-------The confusion matrix for this model is-------')
print(cm_train)

from sklearn.metrics import classification_report
print('\n\n-------Printing the whole report of the model-------')
print(classification_report(df_train_svm_y.values, y_predict_train))

def plot_confusion_matrix(data, labels):
    """Plot confusion matrix using heatmap.
 
    Args:
        data (list of list): List of lists with confusion matrix data.
        labels (list): Labels which will be plotted across x and y axis.
        output_filename (str): Path to output file.
 
    """
    sns.set(color_codes=True)
    plt.figure(1, figsize=(9, 6))
 
    plt.title("Confusion Matrix")
 
    sns.set(font_scale=1.4)
    ax = sns.heatmap(data, annot=True, cmap="Blues", cbar_kws={'label': 'Scale'}, fmt = 'd')
 
    ax.set_xticklabels(labels)
    ax.set_yticklabels(labels)
 
    ax.set(ylabel="True Label", xlabel="Predicted Label")
 
    plt.show()
 

labels = ['A', 'B', 'C', 'D']
plot_confusion_matrix(cm_train, labels)

def plot_multiclass_roc(clf, X_test, y_test, classes, figsize=(17, 6)):
    y_score = clf.decision_function(X_test)

    # structures
    fpr = dict()
    tpr = dict()
    roc_auc = dict()

    # calculate dummies once
    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values
    for i in range(len(classes)):
        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    # roc for each class
    fig, ax = plt.subplots(figsize=figsize)
    ax.plot([0, 1], [0, 1], 'k--')
    ax.set_xlim([0.0, 1.0])
    ax.set_ylim([0.0, 1.05])
    ax.set_xlabel('False Positive Rate')
    ax.set_ylabel('True Positive Rate')
    ax.set_title('Receiver operating characteristic example')
    for i in range(len(classes)):
        ax.plot(fpr[i], tpr[i], label=f'ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))
    ax.legend(loc="best")
    ax.grid(alpha=.4)
    sns.despine()
    plt.show()

classes = {0:'A', 1:'B', 2:'C', 3:'D'}
plot_multiclass_roc(classifier, df_train_svm_X, df_train_svm_y, classes=classes, figsize=(16, 10))

"""RANDOM FOREST"""

df_train_rf_X = df_train.iloc[:, 1:-1]
df_train_rf_y = df_train.iloc[:,-1]

rfc=RandomForestClassifier(random_state=42)

param_grid = { 
    'n_estimators': [200, 500],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [4,5,6,7,8],
    'criterion' :['gini', 'entropy']
}

CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=cv, verbose = 5)
CV_rfc.fit(df_train_rf_X, df_train_rf_y)

CV_rfc.best_params_

#Check performance on train set
y_predict_train = CV_rfc.predict(df_train_rf_X)
acc_train = accuracy_score(df_train_rf_y, y_predict_train)
print("Accuracy for SVM: ", acc_train)

from sklearn.metrics import confusion_matrix
cm_train = confusion_matrix(df_train_rf_y.values, y_predict_train, labels=[0,1,2,3])
print('\n\n-------The confusion matrix for this model is-------')
print(cm_train)

from sklearn.metrics import classification_report
print('\n\n-------Printing the whole report of the model-------')
print(classification_report(df_train_rf_y.values, y_predict_train))

def plot_confusion_matrix(data, labels):
    """Plot confusion matrix using heatmap.
 
    Args:
        data (list of list): List of lists with confusion matrix data.
        labels (list): Labels which will be plotted across x and y axis.
        output_filename (str): Path to output file.
 
    """
    sns.set(color_codes=True)
    plt.figure(1, figsize=(9, 6))
 
    plt.title("Confusion Matrix for Random Forest")
 
    sns.set(font_scale=1.4)
    ax = sns.heatmap(data, annot=True, cmap="Blues", cbar_kws={'label': 'Scale'}, fmt = 'd')
 
    ax.set_xticklabels(labels)
    ax.set_yticklabels(labels)
 
    ax.set(ylabel="True Label", xlabel="Predicted Label")
 
    plt.show()
 

labels = ['A', 'B', 'C', 'D']
plot_confusion_matrix(cm_train, labels)

"""#### **K-MEANS**"""

matrix = df_train.drop(columns=["ID"]).corr()
f, ax = plt.subplots(figsize=(12, 6))
with sns.axes_style("white"):
    sns.heatmap(matrix,mask=np.triu(matrix,1),annot=True,fmt=".2f", vmax=.8,cbar=False,cmap="coolwarm");

model = DecisionTreeRegressor()
model.fit(X_train, y_train)
importance = model.feature_importances_
# plot feature importance
pyplot.bar([x for x in range(len(importance))], importance)
pyplot.show()

from sklearn.metrics import silhouette_score
sse_=[]
for i in range(2,10):
    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)
    kmeans.fit(df_train.drop(columns=["ID","Segmentation","Gender","Spending_Score"]))
    sse_.append( silhouette_score(df_train, kmeans.labels_))

plt.figure(figsize=(12,8))
plt.plot(range(2,10), sse_)
plt.title('The Elbow Method')
plt.xlabel('no of clusters')
plt.ylabel('Silhouette_Score')
plt.show()

kl = KneeLocator(range(2, 10), sse_, curve="convex", direction="decreasing")
kl.elbow

pca = PCA().fit(df_train.drop(columns=["ID","Segmentation","Gender","Spending_Score"]))

plt.figure(figsize=(12,8))
plt.plot(np.cumsum(pca.explained_variance_ratio_), color='k', lw=2)
plt.xlabel('Number of components')
plt.ylabel('Total explained variance')
plt.xlim(0, 11)
plt.yticks(np.arange(0, 1.1, 0.1))
plt.axvline(3.5, c='b')
plt.axhline(0.896, c='r')
plt.show();

pca = decomposition.PCA(n_components=2)
X_reduced_train = pca.fit_transform(df_train.drop(columns=["ID","Segmentation","Gender","Spending_Score"]))

plt.figure(figsize=(10,10))
plt.scatter(X_reduced_train[:, 0], X_reduced_train[:, 1], c=[1]*df_train.shape[0], 
            edgecolor='none', alpha=0.7, s=40,
            cmap=plt.cm.get_cmap('nipy_spectral', 10))
plt.colorbar()
plt.title('MNIST. PCA projection');

f, ax  = plt.subplots(figsize = (10,10))

kmeansmodel = KMeans(n_clusters= 4, init='k-means++',random_state=0)
y_kmeans_train = kmeansmodel.fit_predict(X_reduced_train)

plt.scatter(X_reduced_train[:,0], X_reduced_train[:,1], c=y_kmeans_train, alpha=0.7, s=40)

df_test.isnull().sum()

pca = decomposition.PCA(n_components=2)
X_reduced_test = pca.fit_transform(df_test.drop(columns=["ID","Gender","Spending_Score"]))

plt.figure(figsize=(10,10))
plt.scatter(X_reduced_test[:, 0], X_reduced_test[:, 1], c=[1]*df_test.shape[0], 
            edgecolor='none', alpha=0.7, s=40,
            cmap=plt.cm.get_cmap('nipy_spectral', 10))
plt.colorbar()
plt.title('MNIST. PCA projection');

f, ax  = plt.subplots(figsize = (10,10))

kmeansmodel = KMeans(n_clusters= 4, init='k-means++',random_state=0)
y_kmeans_test = kmeansmodel.fit_predict(X_reduced_test)
    
plt.scatter(X_reduced_test[:,0], X_reduced_test[:,1], c=y_kmeans_test, alpha=0.7, s=40)

df_test=df_test.reset_index()
df_kmeans = pd.DataFrame(y_kmeans_test)
df_kmeans.columns = ["k-means_label"]

df_test=pd.concat([df_test,df_kmeans],axis=1)
df_test

df_train=df_train.reset_index()
df_kmeans = pd.DataFrame(y_kmeans_train)
df_kmeans.columns = ["k-means_label"]

df_train=pd.concat([df_train,df_kmeans],axis=1)
df_train

#df_train['k-means_label'] = df_train['k-means_label'].astype(float)
acc = accuracy_score(df_train.Segmentation, df_train['k-means_label'])
print(acc)

from sklearn.metrics import confusion_matrix
from scipy.optimize import linear_sum_assignment
conf_mat = confusion_matrix(df_train.Segmentation, df_train['k-means_label'] )
conf_mat

df_kmeans.head()

from scipy.optimize import linear_sum_assignment

true_indices, pred_indices = linear_sum_assignment(-conf_mat)
# Re-assign cluster labels afterwards
cluster_labels = np.empty(len(df_kmeans))
for k in range(4):
    # Wherever the GMM assignment was k, re-assign to its best-performing label
    cluster_labels[y_kmeans_train  == pred_indices[k]] = true_indices[k]

correct_preds = (cluster_labels == df_train.Segmentation)
plt.scatter(X_reduced_train[correct_preds, 0], X_reduced_train[correct_preds, 1], c=cluster_labels[correct_preds])
#plt.scatter(X_reduced_train[~correct_preds, 0], X_reduced_train[~correct_preds, 1], color='r', label="Incorrect Cluster Assignments")

plt.scatter(X_reduced_train[~correct_preds, 0], X_reduced_train[~correct_preds, 1], color='r', label="Incorrect Cluster Assignments")